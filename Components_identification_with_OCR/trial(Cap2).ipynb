{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aa1b24d-c03b-4d7e-b97e-2288c1f2d8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gripper...\n",
      "Connecting to gripper...\n",
      "Activating gripper...\n",
      "Gripper auto-calibrated to [3, 248]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 848, 3)\n",
      "{'14': [158.0, 246.0], '16': [340.0, 259.0], '18': [517.0, 255.0], '20': [706.0, 256.0]}\n",
      "D400\n",
      "There is a depth camera with color sensor\n",
      "Depth Scale is:  0.0005000000237487257\n",
      "599.9999715015306\n",
      "00: Custom\n",
      "01: Default\n",
      "02: Hand\n",
      "03: High Accuracy\n",
      "04: High Density\n",
      "14yes\n",
      "0.21050001680850983\n",
      "Camera Points are: -0.09434901922941208 0.0018433876102790236 -0.21050001680850983\n",
      "[119.55760622604967, -690.1442666003134, 121.3318101489173, 1.0]\n",
      "9\n",
      "16yes\n",
      "0.21650001406669617\n",
      "Camera Points are: -0.032042596489191055 -0.0027495943941175938 -0.21650001406669617\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 0 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 273\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    272\u001b[0m val\u001b[38;5;241m=\u001b[39mnum[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 273\u001b[0m \u001b[43mdistance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m### Move downwards in Z axis\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 129\u001b[0m, in \u001b[0;36mdistance\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    127\u001b[0m p \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(value) \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m p1\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m    128\u001b[0m p\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m--> 129\u001b[0m dst_p\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m dst_p\u001b[38;5;241m=\u001b[39mdst_p\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(dst_p)\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 0 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import rtde_control\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "import time\n",
    "#import robotiq_gripper\n",
    "import points2 as p\n",
    "from statistics import mode\n",
    "import re\n",
    "\n",
    "import destination as pd\n",
    "dest=pd.dest_data()\n",
    "\n",
    "import rtde_control\n",
    "import rtde_receive\n",
    "rtde_r = rtde_receive.RTDEReceiveInterface(\"169.254.37.182\")\n",
    "rtde_c = rtde_control.RTDEControlInterface(\"169.254.37.182\")\n",
    "\n",
    "#Gripper\n",
    "ip = \"169.254.37.182\"\n",
    "import robotiq_gripper\n",
    "def log_info(gripper):\n",
    "    print(f\"Pos: {str(gripper.get_current_position()): >3}  \"\n",
    "          f\"Open: {gripper.is_open(): <2}  \"\n",
    "          f\"Closed: {gripper.is_closed(): <2}  \")\n",
    "print(\"Creating gripper...\")\n",
    "gripper = robotiq_gripper.RobotiqGripper()\n",
    "print(\"Connecting to gripper...\")\n",
    "gripper.connect(ip, 63352)\n",
    "print(\"Activating gripper...\")\n",
    "gripper.activate()\n",
    "\n",
    "# Parameters\n",
    "velocity = 0.5\n",
    "acceleration = 0.5\n",
    "dt = 1.0/500  # 2ms\n",
    "lookahead_time = 0.1\n",
    "gain = 300\n",
    "\n",
    "#Jig Location Dictionary\n",
    "jig_coord={1:[-0.36785,-0.68958,0.11495,2.232,2.201,-0.005],2:[-0.30191, -0.68953,0.11495,2.232,2.201,-0.005],3:[-0.24006, -0.68953,0.11495,2.232,2.201,-0.005],4:[-0.18001, -0.68951,0.11495,2.232,2.201,-0.005],5:[-0.11999, -0.68953,0.11495,2.232,2.201,-0.005],6:[-0.05998, -0.68979,0.11495,2.232,2.201,-0.005],7:[-0.00003, -0.69093,0.11495,2.232,2.201,-0.005],8:[0.05998, -0.69145,0.11495,2.232,2.201,-0.005],9:[0.12496,-0.68984,0.11495,2.232,2.201,-0.005]}\n",
    "\n",
    "## Pick and Place 12\n",
    "rtde_c.moveL([0.27967, -0.58801, 0.11500, 2.232, 2.201, -0.005], 0.5, 0.3)\n",
    "rtde_c.moveL([0.27973, -0.58695, -0.04, 2.232, 2.201, -0.005], 0.5, 0.3)\n",
    "gripper.move_and_wait_for_pos(224, 255, 255)\n",
    "rtde_c.moveL([0.27971, -0.58834, 0.11499, 2.223, 2.190, -0.018], 0.5, 0.3)\n",
    "rtde_c.moveL([0.05576, -0.45815, 0.04500, 2.239, 2.201, -0.005], 0.5, 0.3)\n",
    "rtde_c.moveL([0.05576, -0.45745, 0.02513, 2.239, 2.201, -0.005], 0.5, 0.3)\n",
    "rtde_c.moveL([0.11360, -0.45744, 0.02512, 2.239, 2.201, -0.005], 0.5, 0.3)\n",
    "gripper.move_and_wait_for_pos(0, 255, 255)\n",
    "rtde_c.moveL([0.09360, -0.45744, 0.15, 2.239, 2.201, -0.005], 0.5, 0.3)\n",
    "\n",
    "result_f={}\n",
    "depth_dict={}\n",
    "\n",
    "#Capturing position\n",
    "rtde_c.moveL([-0.00772, -0.64201, 0.19098, 0.032, -3.154, -0.017], 0.5, 0.3)\n",
    "time.sleep(1)\n",
    "num=p.point()\n",
    "print(num)\n",
    "\n",
    "def depth_filter(win_data):\n",
    "    x1,y1,x2,y2=win_data[0]-win_data[2]/2,win_data[1]-win_data[3]/2,win_data[0]+3*win_data[2]/2,win_data[1]+3*win_data[3]/2\n",
    "    for i in range(int(y1),int(y2)):\n",
    "        for j in range(int(x1),int(x2)):\n",
    "            d=aligned_depth_frame.get_distance(int(j),int(i))\n",
    "            if d!=0:\n",
    "                k=[j,i]\n",
    "                depth_dict[f'{k}']=round(d, 2)\n",
    "    depth_list=depth_dict.values()\n",
    "    filtered_depth=mode(depth_list)\n",
    "    print(filtered_depth)\n",
    "    corr_pix=list(depth_dict.keys())[list(depth_dict.values()).index(filtered_depth)] #get corresponding pixel of the distance value\n",
    "    print(corr_pix)\n",
    "    print(type(corr_pix))\n",
    "    #print(corr_pix) #A string here\n",
    "    corr_pix=re.split(', ',corr_pix)\n",
    "    pix_corr=[]\n",
    "    for num in corr_pix:\n",
    "        num=re.sub(r\"[\\([{})\\]]\", \"\", num)\n",
    "        num=int(num)\n",
    "        pix_corr.append(num)\n",
    "    \n",
    "    print(pix_corr)\n",
    "    print(type(pix_corr))\n",
    "    a,b=pix_corr[0],pix_corr[1]\n",
    "    depth=aligned_depth_frame.get_distance(int(a),int(b))\n",
    "    return depth\n",
    "def distance(x,y):\n",
    "    #cv2.circle(capture,(x,y),2,(128,0,128),-1)\n",
    "    #print((x,y))\n",
    "    d=depth_frame.get_distance(int(x),int(y))\n",
    "    print(d)\n",
    "    if (d==0.0) :\n",
    "        print('No depth info, Using an window')\n",
    "        depth=depth_filter([int(x),int(y),10,10])\n",
    "        x_w, y_w, z_w = convert_depth_to_phys_coord_using_realsense(int(x),int(y), depth, camera_info)\n",
    "        print('Camera Points are:',x_w, y_w, z_w)\n",
    "        p1=f'{x_w} {y_w} {z_w}'\n",
    "        p = [float(value) for value in p1.split(' ')]\n",
    "        p.append(1.0)\n",
    "        dst_p=np.matmul(k,p)\n",
    "        dst_p=dst_p.tolist()\n",
    "        print(dst_p)\n",
    "        #rtde_c.moveL([dst_p[0]/1000.0, dst_p[1]/1000.0, dst_p[2]/1000.0, 0.032, -3.154, -0.017], 0.5, 0.3)\n",
    "        #time.sleep(5)\n",
    "        #dst_p=(dst_p[0])[:-1]\n",
    "        #print(dst_p)\n",
    "        obj1=dst_p[0]\n",
    "        list=[]\n",
    "        for i in range(1,10):\n",
    "            list.append(abs(obj1-(jig_coord[i][0]*1000)))\n",
    "        obj1abs=list.index(min(list))+1\n",
    "        print(obj1abs)\n",
    "        rtde_c.moveL(jig_coord[obj1abs], 0.5, 0.3)\n",
    "        del list\n",
    "        del p1\n",
    "        del p\n",
    "    else:\n",
    "        x_w, y_w, z_w = convert_depth_to_phys_coord_using_realsense(int(x),int(y), d, camera_info)\n",
    "        print('Camera Points are:',x_w, y_w, z_w)\n",
    "        p1=f'{x_w} {y_w} {z_w}'\n",
    "        p = [float(value) for value in p1.split(' ')]\n",
    "        p.append(1.0)\n",
    "        dst_p=np.matmul(k,p)\n",
    "        dst_p=dst_p.tolist()\n",
    "        print(dst_p)\n",
    "        #rtde_c.moveL([dst_p[0]/1000.0, dst_p[1]/1000.0, dst_p[2]/1000.0, 0.032, -3.154, -0.017], 0.5, 0.3)\n",
    "        #time.sleep(5)\n",
    "        #dst_p=(dst_p[0])[:-1]\n",
    "        #print(dst_p)\n",
    "        obj1=dst_p[0]\n",
    "        list=[]\n",
    "        for i in range(1,10):\n",
    "            list.append(abs(obj1-(jig_coord[i][0]*1000)))\n",
    "        obj1abs=list.index(min(list))+1\n",
    "        print(obj1abs)\n",
    "        rtde_c.moveL(jig_coord[obj1abs], 0.5, 0.3)\n",
    "        del list\n",
    "        del p1\n",
    "        del p\n",
    "\n",
    "def convert_depth_to_phys_coord_using_realsense(x, y, depth, cameraInfo):\n",
    "    _intrinsics = rs.intrinsics()\n",
    "    _intrinsics.width = cameraInfo.width\n",
    "    _intrinsics.height = cameraInfo.height\n",
    "    _intrinsics.ppx = cameraInfo.ppx\n",
    "    _intrinsics.ppy = cameraInfo.ppy\n",
    "    _intrinsics.fx = cameraInfo.fx\n",
    "    _intrinsics.fy = cameraInfo.fy\n",
    "    # _intrinsics.model = cameraInfo.distortion_model\n",
    "    _intrinsics.model  = rs.distortion.none\n",
    "    _intrinsics.coeffs = [i for i in cameraInfo.coeffs]\n",
    "    result = rs.rs2_deproject_pixel_to_point(_intrinsics, [x, y], depth)\n",
    "    # result[0]: right, result[1]: down, result[2]: forward\n",
    "    return result[0], -result[1], -result[2]\n",
    "\"\"\"\n",
    "# Setup the pipeline\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)\n",
    "cfg.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)\n",
    "profile = pipe.start(cfg)\n",
    "\"\"\"\n",
    "\n",
    "k= [[-9.79365051e+02,6.22173726e-01,-1.81205747e+02,-1.09894855e+01],[2.63002626e+00,-9.88050938e+02,-2.41157019e+01,-6.93151121e+02],[1.52250424e+02,7.62100894e+01,-4.30734272e+02,4.48864321e+01],[0.00000000e+00,0.00000000e+00,0.00000000e+00,1.00000000e+00]]\n",
    "\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = rs.pipeline()\n",
    "\n",
    "# Create a config and configure the pipeline to stream\n",
    "config = rs.config()\n",
    "pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "device = pipeline_profile.get_device()\n",
    "device_product_line = str(device.get_info(rs.camera_info.product_line))\n",
    "print(device_product_line)\n",
    "found_rgb = False\n",
    "for s in device.sensors:\n",
    "    if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "        found_rgb = True\n",
    "        print(\"There is a depth camera with color sensor\")\n",
    "        break\n",
    "if not found_rgb:\n",
    "    print(\"The demo requires Depth camera with Color sensor\")\n",
    "    exit(0)\n",
    "config.enable_stream(rs.stream.depth, 848,480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 848,480, rs.format.bgr8, 30)\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "\n",
    "# Setup the 'High Accuracy'-mode\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "print(\"Depth Scale is: \" , depth_scale)\n",
    "clipping_distance_in_meters = 0.3 #1 meter\n",
    "clipping_distance = clipping_distance_in_meters / depth_scale\n",
    "print(clipping_distance)\n",
    "preset_range = depth_sensor.get_option_range(rs.option.visual_preset)\n",
    "for i in range(int(preset_range.max)):\n",
    "    visulpreset = depth_sensor.get_option_value_description(rs.option.visual_preset,i)\n",
    "    print('%02d: %s'%(i,visulpreset))\n",
    "    if visulpreset == \"High Accuracy\":\n",
    "        depth_sensor.set_option(rs.option.visual_preset, i)\n",
    "# enable higher laser-power for better detection\n",
    "depth_sensor.set_option(rs.option.laser_power, 180)\n",
    "# lower the depth unit for better accuracy and shorter distance covered\n",
    "depth_sensor.set_option(rs.option.depth_units, 0.0005)\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "# Skip first frames for auto-exposure to adjust\n",
    "for x in range(5):\n",
    "    pipeline.wait_for_frames()\n",
    "t1=time.time()\n",
    "try:\n",
    "    while True:\n",
    "\n",
    "        # Stores next frameset\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "\n",
    "        if color_frame:\n",
    "            aligned_frames = align.process(frames)\n",
    "\n",
    "            # Get aligned frames\n",
    "            aligned_depth_frame = aligned_frames.get_depth_frame() # aligned_depth_frame is a 640x480 depth image\n",
    "            color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "            # Validate that both frames are valid\n",
    "            if not aligned_depth_frame or not color_frame:\n",
    "                continue\n",
    "\n",
    "            depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "            # Remove background - Set pixels further than clipping_distance to grey\n",
    "            black_color = 0\n",
    "            depth_image_3d = np.dstack((depth_image,depth_image,depth_image)) #depth image is 1 channel, color is 3 channels\n",
    "            bg_removed = np.where((depth_image_3d > clipping_distance) | (depth_image_3d <= 0), black_color, color_image)\n",
    "\n",
    "            # Render images:\n",
    "            #   depth align to color on left\n",
    "            #   depth on right\n",
    "            #depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "            #images = np.hstack((bg_removed, depth_colormap))\n",
    "            camera_info = aligned_depth_frame.profile.as_video_stream_profile().intrinsics\n",
    "            t2=time.time()\n",
    "            if (t2-t1)>3:\n",
    "                cv2.imwrite('captured2.jpg',bg_removed)\n",
    "                # cv2.imshow('captured',bg_removed)\n",
    "                # cv2.waitKey(0)\n",
    "                # # cv2.destroyAllWindows()\n",
    "                break\n",
    "                \n",
    "finally:\n",
    "    numbers=list(num.keys())\n",
    "    z=14\n",
    "    #rtde_c.moveL([-0.16780, -0.70145, 0.160, 0.036, -3.154, -0.017], 0.5, 0.3) #Capturing position\n",
    "    time.sleep(1)\n",
    "    \n",
    "\n",
    "    \n",
    "    for j in range(9):\n",
    "        if f'{z}' in numbers:\n",
    "            print(f'{z}yes')\n",
    "            val=num[f'{z}']\n",
    "            distance(val[0],val[1])\n",
    "            time.sleep(1)\n",
    "            \n",
    "            ### Move downwards in Z axis\n",
    "            actual_p=rtde_r.getActualTCPPose()\n",
    "            actual_p1=actual_p[2]\n",
    "            actual_p[2]=0.015\n",
    "            rtde_c.moveL(actual_p)\n",
    "            ### grip close to 80%\n",
    "            gripper.move_and_wait_for_pos(224, 255, 255)\n",
    "            ### lifts the part in Z axis\n",
    "            actual_p=rtde_r.getActualTCPPose()\n",
    "            actual_p[2]=actual_p1\n",
    "            rtde_c.moveL(actual_p)\n",
    "            ### Call the destination dictionary\n",
    "            for k in range(4):\n",
    "                rtde_c.moveL(dest[z][k], 0.5, 0.3)\n",
    "            ### grippen open \n",
    "            gripper.move_and_wait_for_pos(0, 255, 255)\n",
    "            ### move in Z axis\n",
    "            actual_c=rtde_r.getActualTCPPose()\n",
    "            actual_c[2]+=0.115\n",
    "            rtde_c.moveL(actual_c)\n",
    "            \n",
    "            z+=2\n",
    "        \n",
    "    \n",
    "    # Stop streaming\n",
    "    rtde_c.disconnect()\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d993cbb4-9ece-4d66-93d0-31a9760f8499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aeaebe-ce3a-4264-8fdb-c8389985068b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce87c74b-ef9e-481c-8846-f6f9ce67d553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
