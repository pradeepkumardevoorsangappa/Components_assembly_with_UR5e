{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "544df0ca-c9e7-42c6-a5f1-8c68d447c341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D400\n",
      "There is a depth camera with color sensor\n",
      "Depth Scale is:  0.0005000000237487257\n",
      "499.9999762512755\n",
      "00: Custom\n",
      "01: Default\n",
      "02: Hand\n",
      "03: High Accuracy\n",
      "04: High Density\n",
      "1\n",
      "(130, 255)\n",
      "0.18950000405311584\n",
      "[ 848x480  p[429.725 251.306]  f[606.24 605.852]  None [0 0 0 0 0] ]\n",
      "Points are: -0.09368883818387985 -0.0011555579258129 -0.18950000405311584\n",
      "0.19\n",
      "[125, 250]\n",
      "<class 'str'>\n",
      "[125, 250]\n",
      "<class 'list'>\n",
      "[ 848x480  p[429.725 251.306]  f[606.24 605.852]  None [0 0 0 0 0] ]\n",
      "Points according to window: -0.09393604099750519 -0.0011586069595068693 -0.1900000125169754\n",
      "1\n",
      "(751, 137)\n",
      "0.2900000214576721\n",
      "[ 848x480  p[429.725 251.306]  f[606.24 605.852]  None [0 0 0 0 0] ]\n",
      "Points are: 0.15368449687957764 0.054714057594537735 -0.2900000214576721\n",
      "0.19\n",
      "[125, 250]\n",
      "<class 'str'>\n",
      "[125, 250]\n",
      "<class 'list'>\n",
      "[ 848x480  p[429.725 251.306]  f[606.24 605.852]  None [0 0 0 0 0] ]\n",
      "Points according to window: 0.1006898432970047 0.03584713861346245 -0.1900000125169754\n",
      "1\n",
      "(188, 404)\n",
      "0.27400001883506775\n",
      "[ 848x480  p[429.725 251.306]  f[606.24 605.852]  None [0 0 0 0 0] ]\n",
      "Points are: -0.10925161838531494 -0.06905695050954819 -0.27400001883506775\n",
      "0.19\n",
      "[125, 250]\n",
      "<class 'str'>\n",
      "[125, 250]\n",
      "<class 'list'>\n",
      "[ 848x480  p[429.725 251.306]  f[606.24 605.852]  None [0 0 0 0 0] ]\n",
      "Points according to window: -0.0757584273815155 -0.0478862039744854 -0.1900000125169754\n",
      "1\n",
      "(639, 389)\n",
      "0.2720000147819519\n",
      "[ 848x480  p[429.725 251.306]  f[606.24 605.852]  None [0 0 0 0 0] ]\n",
      "Points are: 0.09389473497867584 -0.06181855872273445 -0.2720000147819519\n",
      "0.19\n",
      "[125, 250]\n",
      "<class 'str'>\n",
      "[125, 250]\n",
      "<class 'list'>\n",
      "[ 848x480  p[429.725 251.306]  f[606.24 605.852]  None [0 0 0 0 0] ]\n",
      "Points according to window: 0.06558823585510254 -0.04318208247423172 -0.1900000125169754\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "from statistics import mode\n",
    "import re\n",
    "depth_dict={}\n",
    "def depth_filter(win_data):\n",
    "    x1,y1,x2,y2=win_data[0]-win_data[2]/2,win_data[1]-win_data[3]/2,win_data[0]+3*win_data[2]/2,win_data[1]+3*win_data[3]/2\n",
    "    for i in range(int(y1),int(y2)):\n",
    "        for j in range(int(x1),int(x2)):\n",
    "            d=aligned_depth_frame.get_distance(int(j),int(i))\n",
    "            if d!=0:\n",
    "                k=[j,i]\n",
    "                depth_dict[f'{k}']=round(d, 2)\n",
    "    depth_list=depth_dict.values()\n",
    "    filtered_depth=mode(depth_list)\n",
    "    print(filtered_depth)\n",
    "    corr_pix=list(depth_dict.keys())[list(depth_dict.values()).index(filtered_depth)] #get corresponding pixel of the distance value\n",
    "    print(corr_pix)\n",
    "    print(type(corr_pix))\n",
    "    #print(corr_pix) #A string here\n",
    "    corr_pix=re.split(', ',corr_pix)\n",
    "    pix_corr=[]\n",
    "    for num in corr_pix:\n",
    "        num=re.sub(r\"[\\([{})\\]]\", \"\", num)\n",
    "        num=int(num)\n",
    "        pix_corr.append(num)\n",
    "    \n",
    "    print(pix_corr)\n",
    "    print(type(pix_corr))\n",
    "    a,b=pix_corr[0],pix_corr[1]\n",
    "    depth=aligned_depth_frame.get_distance(int(a),int(b))\n",
    "    return depth\n",
    "\n",
    "def distance(event,x,y,flags,param):\n",
    "    if event==cv2.EVENT_LBUTTONDOWN:\n",
    "        print(event)\n",
    "        cv2.circle(capture,(x,y),2,(128,0,128),-1)\n",
    "        print((x,y))\n",
    "        window=[int(x),int(y),10,10]\n",
    "        d=depth_frame.get_distance(int(x),int(y))\n",
    "        print(d)\n",
    "        if (d==0.0) :\n",
    "            print('Depth is zero, use an window')\n",
    "            d1=depth_filter(window)\n",
    "            x_w1, y_w1, z_w1= convert_depth_to_phys_coord_using_realsense(int(x),int(y), d1, camera_info)\n",
    "            print('Points according to window:',x_w1, y_w1, z_w1)\n",
    "        else:\n",
    "            x_w, y_w, z_w = convert_depth_to_phys_coord_using_realsense(int(x),int(y), d, camera_info)\n",
    "            print('Points are:',x_w, y_w, z_w)\n",
    "            d1=depth_filter(window)\n",
    "            x_w1, y_w1, z_w1= convert_depth_to_phys_coord_using_realsense(int(x),int(y), d1, camera_info)\n",
    "            print('Points according to window:',x_w1, y_w1, z_w1)\n",
    "\n",
    "def convert_depth_to_phys_coord_using_realsense(x, y, depth, cameraInfo):\n",
    "    _intrinsics = rs.intrinsics()\n",
    "    _intrinsics.width = cameraInfo.width\n",
    "    _intrinsics.height = cameraInfo.height\n",
    "    _intrinsics.ppx = cameraInfo.ppx\n",
    "    _intrinsics.ppy = cameraInfo.ppy\n",
    "    _intrinsics.fx = cameraInfo.fx\n",
    "    _intrinsics.fy = cameraInfo.fy\n",
    "    # _intrinsics.model = cameraInfo.distortion_model\n",
    "    _intrinsics.model  = rs.distortion.none\n",
    "    _intrinsics.coeffs = [i for i in cameraInfo.coeffs]\n",
    "    print(_intrinsics)\n",
    "    result = rs.rs2_deproject_pixel_to_point(_intrinsics, [x, y], depth)\n",
    "    # result[0]: right, result[1]: down, result[2]: forward\n",
    "    return result[0], -result[1], -result[2]\n",
    "\"\"\"\n",
    "# Setup the pipeline\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)\n",
    "cfg.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)\n",
    "profile = pipe.start(cfg)\n",
    "\"\"\"\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = rs.pipeline()\n",
    "\n",
    "# Create a config and configure the pipeline to stream\n",
    "config = rs.config()\n",
    "pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "device = pipeline_profile.get_device()\n",
    "device_product_line = str(device.get_info(rs.camera_info.product_line))\n",
    "print(device_product_line)\n",
    "found_rgb = False\n",
    "for s in device.sensors:\n",
    "    if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "        found_rgb = True\n",
    "        print(\"There is a depth camera with color sensor\")\n",
    "        break\n",
    "if not found_rgb:\n",
    "    print(\"The demo requires Depth camera with Color sensor\")\n",
    "    exit(0)\n",
    "config.enable_stream(rs.stream.depth, 848,480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 848,480, rs.format.bgr8, 30)\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "\n",
    "# Setup the 'High Accuracy'-mode\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "print(\"Depth Scale is: \" , depth_scale)\n",
    "clipping_distance_in_meters = 0.25 #1 meter\n",
    "clipping_distance = clipping_distance_in_meters / depth_scale\n",
    "print(clipping_distance)\n",
    "preset_range = depth_sensor.get_option_range(rs.option.visual_preset)\n",
    "for i in range(int(preset_range.max)):\n",
    "    visulpreset = depth_sensor.get_option_value_description(rs.option.visual_preset,i)\n",
    "    print('%02d: %s'%(i,visulpreset))\n",
    "    if visulpreset == \"High Accuracy\":\n",
    "        depth_sensor.set_option(rs.option.visual_preset, i)\n",
    "# enable higher laser-power for better detection\n",
    "depth_sensor.set_option(rs.option.laser_power, 180)\n",
    "# lower the depth unit for better accuracy and shorter distance covered\n",
    "depth_sensor.set_option(rs.option.depth_units, 0.0005)\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "# Skip first frames for auto-exposure to adjust\n",
    "for x in range(5):\n",
    "    pipeline.wait_for_frames()\n",
    "try:\n",
    "    while True:\n",
    "\n",
    "        # Stores next frameset\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "\n",
    "        if color_frame:\n",
    "            aligned_frames = align.process(frames)\n",
    "\n",
    "            # Get aligned frames\n",
    "            aligned_depth_frame = aligned_frames.get_depth_frame() # aligned_depth_frame is a 640x480 depth image\n",
    "            color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "            # Validate that both frames are valid\n",
    "            if not aligned_depth_frame or not color_frame:\n",
    "                continue\n",
    "\n",
    "            depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "            # Remove background - Set pixels further than clipping_distance to grey\n",
    "            black_color = 0\n",
    "            depth_image_3d = np.dstack((depth_image,depth_image,depth_image)) #depth image is 1 channel, color is 3 channels\n",
    "            bg_removed = np.where((depth_image_3d > clipping_distance) | (depth_image_3d <= 0), black_color, color_image)\n",
    "\n",
    "            # Render images:\n",
    "            #   depth align to color on left\n",
    "            #   depth on right\n",
    "            #depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "            #images = np.hstack((bg_removed, depth_colormap))\n",
    "            cv2.namedWindow('depth_cut', cv2.WINDOW_NORMAL)\n",
    "            cv2.imshow('depth_cut', bg_removed)\n",
    "            camera_info = aligned_depth_frame.profile.as_video_stream_profile().intrinsics\n",
    "            if cv2.waitKey(1) & 0xFF==27:\n",
    "                capture=bg_removed\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "\n",
    "finally:\n",
    "    while True:\n",
    "        cv2.imshow('object',capture)\n",
    "        cv2.setMouseCallback('object',distance)\n",
    "        if cv2.waitKey(10) & 0xFF==27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    # Stop streaming\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3ae09-5e7f-4967-bdb3-4103a34ac030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
