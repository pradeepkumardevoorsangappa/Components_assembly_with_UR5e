{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e004b65-349e-40a7-87d8-682175947f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gripper...\n",
      "Connecting to gripper...\n",
      "Activating gripper...\n",
      "Gripper auto-calibrated to [3, 248]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 848, 3)\n",
      "{'19': [119.0, 378.0], '17': [326.0, 374.0], '15': [503.0, 363.0], '13': [684.0, 371.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 848, 3)\n",
      "{'14': [161.0, 365.0], '16': [327.0, 364.0], '18': [505.0, 369.0], '20': [700.0, 378.0]}\n",
      "D400\n",
      "There is a depth camera with color sensor\n",
      "Depth Scale is:  0.0010000000474974513\n",
      "299.9999857507653\n",
      "00: Custom\n",
      "01: Default\n",
      "02: Hand\n",
      "03: High Accuracy\n",
      "04: High Density\n",
      "14yes\n",
      "0.2720000147819519\n",
      "Camera Points are: -0.1205681711435318 -0.05104365199804306 -0.2720000147819519\n",
      "[156.34697542438414, -636.4750189473385, 139.79956399151266, 1.0]\n",
      "[524.2069754243842, 458.84697542438414, 397.94697542438416, 337.19697542438416, 276.19697542438416, 215.19697542438414, 157.38697542438413, 96.24697542438415, 31.34697542438414]\n",
      "9\n",
      "15yes\n",
      "0.27250000834465027\n",
      "Camera Points are: 0.03293643519282341 -0.05023791640996933 -0.27250000834465027\n",
      "[-301.53187188189605, -656.5911599439329, 127.38085412529422, 1.0]\n",
      "[66.32812811810396, 0.968128118103948, 59.93187188189603, 120.68187188189603, 181.68187188189606, 242.68187188189606, 300.49187188189603, 361.6318718818961, 426.53187188189605]\n",
      "2\n",
      "16yes\n",
      "0.27250000834465027\n",
      "Camera Points are: -0.04617414250969887 -0.050687700510025024 -0.27250000834465027\n",
      "[83.57888694800239, -636.6190012043531, 151.36857785203935, 1.0]\n",
      "[451.4388869480024, 386.0788869480024, 325.1788869480024, 264.4288869480024, 203.4288869480024, 142.4288869480024, 84.6188869480024, 23.47888694800239, 41.42111305199761]\n",
      "8\n",
      "17yes\n",
      "0.2720000147819519\n",
      "Camera Points are: -0.0465380884706974 -0.055084243416786194 -0.2720000147819519\n",
      "[-244.20329571437236, -654.4674861000482, 133.8882730833763, 1.0]\n",
      "[123.65670428562765, 58.29670428562764, 2.6032957143723365, 63.35329571437234, 124.35329571437236, 185.35329571437236, 243.16329571437237, 304.3032957143724, 369.20329571437236]\n",
      "3\n",
      "18yes\n",
      "0.27250000834465027\n",
      "Camera Points are: 0.03383541852235794 -0.05293659865856171 -0.27250000834465027\n",
      "[5.2189199220139955, -634.1865480326596, 163.3786787142724, 1.0]\n",
      "[373.078919922014, 307.718919922014, 246.818919922014, 186.068919922014, 125.06891992201399, 64.068919922014, 6.2589199220139955, 54.881080077986006, 119.781080077986]\n",
      "7\n",
      "19yes\n",
      "0.2720000147819519\n",
      "Camera Points are: -0.13941219449043274 -0.05688006058335304 -0.2720000147819519\n",
      "[-177.05510473167962, -654.8728818377712, 141.67132621283878, 1.0]\n",
      "[190.8048952683204, 125.44489526832038, 64.5448952683204, 3.7948952683204027, 57.205104731679626, 118.20510473167963, 176.01510473167963, 237.15510473167961, 302.05510473167965]\n",
      "4\n",
      "20yes\n",
      "0.27300000190734863\n",
      "Camera Points are: 0.12170924991369247 -0.057089176028966904 -0.27300000190734863\n",
      "[-80.75362135763685, -629.8404218868772, 176.65640287270216, 1.0]\n",
      "[287.10637864236315, 221.74637864236314, 160.84637864236316, 100.09637864236318, 39.09637864236315, 21.903621357636844, 79.71362135763684, 140.85362135763685, 205.75362135763686]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#Import\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import rtde_control\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "import time\n",
    "import points1 as pl\n",
    "import points2 as pr\n",
    "from statistics import mode\n",
    "import re\n",
    "\n",
    "#Rtde Control\n",
    "import rtde_control\n",
    "import rtde_receive\n",
    "\n",
    "\n",
    "rtde_r = rtde_receive.RTDEReceiveInterface(\"192.168.31.99\")\n",
    "rtde_c = rtde_control.RTDEControlInterface(\"192.168.31.99\")\n",
    "\n",
    "#Gripper\n",
    "ip = \"192.168.31.99\"\n",
    "import robotiq_gripper\n",
    "def log_info(gripper):\n",
    "    print(f\"Pos: {str(gripper.get_current_position()): >3}  \"\n",
    "          f\"Open: {gripper.is_open(): <2}  \"\n",
    "          f\"Closed: {gripper.is_closed(): <2}  \")\n",
    "print(\"Creating gripper...\")\n",
    "gripper = robotiq_gripper.RobotiqGripper()\n",
    "print(\"Connecting to gripper...\")\n",
    "gripper.connect(ip, 63352)\n",
    "print(\"Activating gripper...\")\n",
    "gripper.activate()\n",
    "\n",
    "import destination as pd\n",
    "dest=pd.dest_data()\n",
    "\n",
    "#Parameters\n",
    "velocity = 0.5\n",
    "acceleration = 0.5\n",
    "dt = 1.0/500  # 2ms\n",
    "lookahead_time = 0.1\n",
    "gain = 300\n",
    "\n",
    "#Jig Location Dictionary\n",
    "jig_coord={1:[-0.36786,-0.68974,0.1500,2.244,2.188,-0.005],2:[-0.3025, -0.690, 0.1498, 2.244, 2.188, -0.005],3:[-0.2416, -0.690, 0.150, 2.244, 2.188, -0.005],4:[-0.18085, -0.690, 0.1506, 2.244, 2.188, -0.005],5:[-0.11985, -0.690, 0.1500, 2.244, 2.188, -0.005],6:[-0.05885, -0.69, 0.1500, 2.244, 2.188, -0.005],7:[-0.00104, -0.690, 0.1500, 2.244, 2.188, -0.005],8:[0.0601, -0.6913, 0.1501, 2.244, 2.188, -0.005],9:[0.125,-0.6895,0.1502,2.244,2.188,-0.005]}\n",
    "\n",
    "\n",
    "# ## Pick and Place 11\n",
    "# rtde_c.moveL([-0.53246, -0.58505, 0.114994, 2.223, 2.190, -0.018], 0.5, 0.3)\n",
    "# rtde_c.moveL([-0.53250, -0.58502, -0.040002, 2.223, 2.190, -0.018], 0.5, 0.3)\n",
    "# gripper.move_and_wait_for_pos(224, 255, 255)\n",
    "# rtde_c.moveL([-0.53251, -0.585, 0.11496, 2.223, 2.19, -0.018], 0.5, 0.3)\n",
    "# rtde_c.moveL([-0.27381, -0.45546, 0.04498, 2.232, 2.201, -0.005], 0.5, 0.3)\n",
    "# rtde_c.moveL([-0.27383, -0.45555, 0.02471, 2.232, 2.201, -0.005], 0.5, 0.3)\n",
    "# rtde_c.moveL([-0.30992, -0.45553, 0.02472, 2.232, 2.201, -0.005], 0.5, 0.3)\n",
    "# gripper.move_and_wait_for_pos(0, 255, 255)\n",
    "# rtde_c.moveL([-0.30992, -0.45553, 0.15, 2.232, 2.201, -0.005], 0.5, 0.3)\n",
    "\n",
    "# ## Pick and Place 12\n",
    "# rtde_c.moveL([0.27967, -0.58801, 0.11500, 2.232, 2.201, -0.005], 0.5, 0.3)\n",
    "# rtde_c.moveL([0.27973, -0.58695, -0.04, 2.232, 2.201, -0.005], 0.5, 0.3)\n",
    "# gripper.move_and_wait_for_pos(224, 255, 255)\n",
    "# rtde_c.moveL([0.27971, -0.58834, 0.11499, 2.223, 2.190, -0.018], 0.5, 0.3)\n",
    "# rtde_c.moveL([0.05576, -0.45815, 0.04500, 2.239, 2.201, -0.005], 0.5, 0.3)\n",
    "# rtde_c.moveL([0.05576, -0.45745, 0.02513, 2.239, 2.201, -0.005], 0.5, 0.3)\n",
    "# rtde_c.moveL([0.09360, -0.45744, 0.02512, 2.239, 2.201, -0.005], 0.5, 0.3)\n",
    "# gripper.move_and_wait_for_pos(0, 255, 255)\n",
    "# rtde_c.moveL([0.09360, -0.45744, 0.15, 2.239, 2.201, -0.005], 0.5, 0.3)\n",
    "\n",
    "# ## Pick and Place 13\n",
    "# rtde_c.moveL([-0.36783,-0.68956,0.11500,2.244,2.188,-0.005], 0.5, 0.3)\n",
    "# rtde_c.moveL([-0.36786,-0.68974,0.01500,2.244,2.188,-0.005], 0.5, 0.3)\n",
    "# gripper.move_and_wait_for_pos(224, 255, 255)\n",
    "# rtde_c.moveL([-0.36776,-0.68965,0.11495,2.244,2.188,-0.005], 0.5, 0.3)\n",
    "# rtde_c.moveL([-0.36625,-0.55850,0.11500,2.244,2.188,-0.005], 0.5, 0.3)\n",
    "# rtde_c.moveL([-0.3663,-0.55850,-0.001,2.244,2.188,-0.005], 0.5, 0.3)\n",
    "# rtde_c.moveL([-0.36628,-0.45565,-0.001,2.244,2.188,-0.005], 0.5, 0.3)\n",
    "# gripper.move_and_wait_for_pos(0, 255, 255)\n",
    "# rtde_c.moveL([-0.36628,-0.45565,0.15,2.244,2.188,-0.005], 0.5, 0.3)\n",
    "\n",
    "## IMAGE PROCESSING\n",
    "result_f={}\n",
    "depth_dict={}\n",
    "\n",
    "## dest_dict={}#########################################################################\n",
    "# rtde_c = rtde_control.RTDEControlInterface(\"169.254.37.182\")\n",
    "\n",
    "#Capturing position\n",
    "rtde_c.moveL([-0.30898, -0.64203, 0.19003, 0.032, -3.154, -0.017], 0.5, 0.3) \n",
    "time.sleep(1)\n",
    "numl=pl.point()\n",
    "print(numl)\n",
    "numbersL=list(numl.keys())\n",
    "rtde_c.moveL([-0.00772, -0.64201, 0.19098, 0.032, -3.154, -0.017], 0.5, 0.3)\n",
    "time.sleep(1)\n",
    "numr=pr.point()\n",
    "print(numr)\n",
    "numbersR=list(numr.keys())\n",
    "\n",
    "\n",
    "def depth_filter(win_data):\n",
    "    x1,y1,x2,y2=win_data[0]-win_data[2]/2,win_data[1]-win_data[3]/2,win_data[0]+3*win_data[2]/2,win_data[1]+3*win_data[3]/2\n",
    "    for i in range(int(y1),int(y2)):\n",
    "        for j in range(int(x1),int(x2)):\n",
    "            d=aligned_depth_frame.get_distance(int(j),int(i))\n",
    "            if d!=0:\n",
    "                k=[j,i]\n",
    "                depth_dict[f'{k}']=round(d, 2)\n",
    "    depth_list=depth_dict.values()\n",
    "    filtered_depth=mode(depth_list)\n",
    "    print(filtered_depth)\n",
    "    corr_pix=list(depth_dict.keys())[list(depth_dict.values()).index(filtered_depth)] #get corresponding pixel of the distance value\n",
    "    print(corr_pix)\n",
    "    print(type(corr_pix))\n",
    "    #print(corr_pix) #A string here\n",
    "    corr_pix=re.split(', ',corr_pix)\n",
    "    pix_corr=[]\n",
    "    for num in corr_pix:\n",
    "        num=re.sub(r\"[\\([{})\\]]\", \"\", num)\n",
    "        num=int(num)\n",
    "        pix_corr.append(num)\n",
    "    \n",
    "    print(pix_corr)\n",
    "    print(type(pix_corr))\n",
    "    a,b=pix_corr[0],pix_corr[1]\n",
    "    depth=aligned_depth_frame.get_distance(int(a),int(b))\n",
    "    return depth\n",
    "def distance(x,y,kt):\n",
    "    #cv2.circle(capture,(x,y),2,(128,0,128),-1)\n",
    "    #print((x,y))\n",
    "    d=depth_frame.get_distance(int(x),int(y))\n",
    "    print(d)\n",
    "    if (d==0.0) :\n",
    "        print('No depth info, Using an window')\n",
    "        depth=depth_filter([int(x),int(y),10,10])\n",
    "        x_w, y_w, z_w = convert_depth_to_phys_coord_using_realsense(int(x),int(y), depth, camera_info)\n",
    "        print('Camera Points are:',x_w, y_w, z_w)\n",
    "        p1=f'{x_w} {y_w} {z_w}'\n",
    "        p = [float(value) for value in p1.split(' ')]\n",
    "        p.append(1.0)\n",
    "        dst_p=np.matmul(kt,p)\n",
    "        dst_p=dst_p.tolist()\n",
    "        print(dst_p)\n",
    "        #rtde_c.moveL([dst_p[0]/1000.0, dst_p[1]/1000.0, dst_p[2]/1000.0, 0.032, -3.154, -0.017], 0.5, 0.3)\n",
    "        #time.sleep(5)\n",
    "        #dst_p=(dst_p[0])[:-1]\n",
    "        #print(dst_p)\n",
    "        obj1=dst_p[0]\n",
    "        list=[]\n",
    "        for i in range(1,10):\n",
    "            list.append(abs(obj1-(jig_coord[i][0]*1000)))\n",
    "        obj1abs=list.index(min(list))+1\n",
    "        print(list)\n",
    "        print(obj1abs)\n",
    "        rtde_c.moveL(jig_coord[obj1abs], 0.5, 0.3)\n",
    "        del list\n",
    "        del p1\n",
    "        del p\n",
    "    else:\n",
    "        x_w, y_w, z_w = convert_depth_to_phys_coord_using_realsense(int(x),int(y), d, camera_info)\n",
    "        print('Camera Points are:',x_w, y_w, z_w)\n",
    "        p1=f'{x_w} {y_w} {z_w}'\n",
    "        p = [float(value) for value in p1.split(' ')]\n",
    "        p.append(1.0)\n",
    "        dst_p=np.matmul(kt,p)\n",
    "        dst_p=dst_p.tolist()\n",
    "        print(dst_p)\n",
    "        #rtde_c.moveL([dst_p[0]/1000.0, dst_p[1]/1000.0, dst_p[2]/1000.0, 0.032, -3.154, -0.017], 0.5, 0.3)\n",
    "        #time.sleep(5)\n",
    "        #dst_p=(dst_p[0])[:-1]\n",
    "        #print(dst_p)\n",
    "        obj1=dst_p[0]\n",
    "        list=[]\n",
    "        for i in range(1,10):\n",
    "            list.append(abs(obj1-(jig_coord[i][0]*1000)))\n",
    "        print(list)\n",
    "        obj1abs=list.index(min(list))+1\n",
    "        print(obj1abs)\n",
    "        rtde_c.moveL(jig_coord[obj1abs], 0.5, 0.3)\n",
    "        del list\n",
    "        del p1\n",
    "        del p\n",
    "\n",
    "def convert_depth_to_phys_coord_using_realsense(x, y, depth, cameraInfo):\n",
    "    _intrinsics = rs.intrinsics()\n",
    "    _intrinsics.width = cameraInfo.width\n",
    "    _intrinsics.height = cameraInfo.height\n",
    "    _intrinsics.ppx = cameraInfo.ppx\n",
    "    _intrinsics.ppy = cameraInfo.ppy\n",
    "    _intrinsics.fx = cameraInfo.fx\n",
    "    _intrinsics.fy = cameraInfo.fy\n",
    "    # _intrinsics.model = cameraInfo.distortion_model\n",
    "    _intrinsics.model  = rs.distortion.none\n",
    "    _intrinsics.coeffs = [i for i in cameraInfo.coeffs]\n",
    "    result = rs.rs2_deproject_pixel_to_point(_intrinsics, [x, y], depth)\n",
    "    # result[0]: right, result[1]: down, result[2]: forward\n",
    "    return result[0], -result[1], -result[2]\n",
    "\"\"\"\n",
    "# Setup the pipeline\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)\n",
    "cfg.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)\n",
    "profile = pipe.start(cfg)\n",
    "\"\"\"\n",
    "\n",
    "kl= [[-724.60538548,82.90733245,285.41238816,-195.72598377],[18.67714179,-740.17953151,41.7580128,-683.01233701],[-84.6609671,44.4134883,-11.45772205,129.27829634],[0,0,0,1]]\n",
    "kr= [[-9.79365051e+02,6.22173726e-01,-1.81205747e+02,-1.09894855e+01],[2.63002626e+00,-9.88050938e+02,-2.41157019e+01,-6.93151121e+02],[1.52250424e+02,7.62100894e+01,-4.30734272e+02,4.48864321e+01],[0.00000000e+00,0.00000000e+00,0.00000000e+00,1.00000000e+00]]\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = rs.pipeline()\n",
    "\n",
    "# Create a config and configure the pipeline to stream\n",
    "config = rs.config()\n",
    "pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "device = pipeline_profile.get_device()\n",
    "device_product_line = str(device.get_info(rs.camera_info.product_line))\n",
    "print(device_product_line)\n",
    "found_rgb = False\n",
    "for s in device.sensors:\n",
    "    if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "        found_rgb = True\n",
    "        print(\"There is a depth camera with color sensor\")\n",
    "        break\n",
    "if not found_rgb:\n",
    "    print(\"The demo requires Depth camera with Color sensor\")\n",
    "    exit(0)\n",
    "config.enable_stream(rs.stream.depth, 848,480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 848,480, rs.format.bgr8, 30)\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "# Setup the 'High Accuracy'-mode\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "print(\"Depth Scale is: \" , depth_scale)\n",
    "clipping_distance_in_meters = 0.3 #1 meter\n",
    "clipping_distance = clipping_distance_in_meters / depth_scale\n",
    "print(clipping_distance)\n",
    "preset_range = depth_sensor.get_option_range(rs.option.visual_preset)\n",
    "for i in range(int(preset_range.max)):\n",
    "    visulpreset = depth_sensor.get_option_value_description(rs.option.visual_preset,i)\n",
    "    print('%02d: %s'%(i,visulpreset))\n",
    "    if visulpreset == \"High Accuracy\":\n",
    "        depth_sensor.set_option(rs.option.visual_preset, i)\n",
    "# enable higher laser-power for better detection\n",
    "depth_sensor.set_option(rs.option.laser_power, 180)\n",
    "# lower the depth unit for better accuracy and shorter distance covered\n",
    "depth_sensor.set_option(rs.option.depth_units, 0.0005)\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "# Skip first frames for auto-exposure to adjust\n",
    "for x in range(5):\n",
    "    pipeline.wait_for_frames()\n",
    "t1=time.time()\n",
    "try:\n",
    "    while True:\n",
    "        # Stores next frameset\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "\n",
    "        if color_frame:\n",
    "            aligned_frames = align.process(frames)\n",
    "            # Get aligned frames\n",
    "            aligned_depth_frame = aligned_frames.get_depth_frame() # aligned_depth_frame is a 640x480 depth image\n",
    "            color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "            # Validate that both frames are valid\n",
    "            if not aligned_depth_frame or not color_frame:\n",
    "                continue\n",
    "\n",
    "            depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "            # Remove background - Set pixels further than clipping_distance to grey\n",
    "            black_color = 0\n",
    "            depth_image_3d = np.dstack((depth_image,depth_image,depth_image)) #depth image is 1 channel, color is 3 channels\n",
    "            bg_removed = np.where((depth_image_3d > clipping_distance) | (depth_image_3d <= 0), black_color, color_image)\n",
    "\n",
    "            # Render images:\n",
    "            #   depth align to color on left\n",
    "            #   depth on right\n",
    "            #depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "            #images = np.hstack((bg_removed, depth_colormap))\n",
    "            camera_info = aligned_depth_frame.profile.as_video_stream_profile().intrinsics\n",
    "            t2=time.time()\n",
    "            if (t2-t1)>3:\n",
    "                cv2.imwrite('captured1.jpg',bg_removed)\n",
    "                # cv2.imshow('captured',bg_removed)\n",
    "                # cv2.waitKey(0)\n",
    "                # # cv2.destroyAllWindows()\n",
    "                break\n",
    "                \n",
    "finally:\n",
    "    #numbers=list(num.keys())\n",
    "    z=14\n",
    "\n",
    "    for j in range(9):\n",
    "        if f'{z}' in numbersL:\n",
    "            print(f'{z}yes')\n",
    "            val=numl[f'{z}']\n",
    "            distance(val[0],val[1],kl)\n",
    "            time.sleep(1)\n",
    "            \n",
    "            ### Move downwards in Z axis\n",
    "            actual_p=rtde_r.getActualTCPPose()\n",
    "            z_pos=actual_p[2]\n",
    "            actual_p[2]=0.015\n",
    "            rtde_c.moveL(actual_p)\n",
    "            ### grip close to 80%\n",
    "            #gripper.move_and_wait_for_pos(224, 255, 255)\n",
    "            ### lifts the part in Z axis\n",
    "            actual_p2=rtde_r.getActualTCPPose()\n",
    "            actual_p2[2]=z_pos\n",
    "            rtde_c.moveL(actual_p2)\n",
    "            ### Call the destination dictionary\n",
    "            for k in range(3):\n",
    "                rtde_c.moveL(dest[z][k], 0.5, 0.3)\n",
    "            ### grippen open \n",
    "            #gripper.move_and_wait_for_pos(0, 255, 255)\n",
    "            ### move in Z axis\n",
    "            actual_c=rtde_r.getActualTCPPose()\n",
    "            actual_c[2]+=0.115\n",
    "            rtde_c.moveL(actual_c)\n",
    "            \n",
    "        elif f'{z}' in numbersR:\n",
    "            print(f'{z}yes')\n",
    "            val=numr[f'{z}']\n",
    "            distance(val[0],val[1],kr)\n",
    "            time.sleep(1)\n",
    "            \n",
    "            ### Move downwards in Z axis\n",
    "            actual_p=rtde_r.getActualTCPPose()\n",
    "            actual_p1=actual_p[2]\n",
    "            actual_p[2]=0.015\n",
    "            rtde_c.moveL(actual_p)\n",
    "            ### grip close to 80%\n",
    "            #gripper.move_and_wait_for_pos(224, 255, 255)\n",
    "            ### lifts the part in Z axis\n",
    "            actual_p=rtde_r.getActualTCPPose()\n",
    "            actual_p[2]=actual_p1\n",
    "            rtde_c.moveL(actual_p)\n",
    "            # ### Call the destination dictionary\n",
    "            for k in range(3):\n",
    "                rtde_c.moveL(dest[z][k], 0.5, 0.3)\n",
    "            ## grippen open \n",
    "            #gripper.move_and_wait_for_pos(0, 255, 255)\n",
    "            ### move in Z axis\n",
    "            actual_c=rtde_r.getActualTCPPose()\n",
    "            actual_c[2]+=0.15\n",
    "            rtde_c.moveL(actual_c)\n",
    "            \n",
    "        z+=1\n",
    "    # Stop streaming\n",
    "    rtde_c.disconnect()\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa26d9d-fd5d-4685-b56b-8bb3bdabee0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24914c2-6040-4b2d-b623-30d84c2c43f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cc4973-ba11-4cae-99fa-796e033db106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
