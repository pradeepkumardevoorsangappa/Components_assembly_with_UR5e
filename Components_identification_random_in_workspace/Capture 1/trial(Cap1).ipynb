{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac66ca30-dcc4-4ecf-91da-1ab437c5a274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import points\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4ebbc9-0520-474f-bffd-8873fbdc5c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num=points.point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a66aa81-e36a-4710-8a51-0c0df0ecca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4ddc7-f885-4d1a-95e1-d57b6834ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_detected=list(num.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d4e25d-9a04-4b60-9a1a-3408c1c2f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numbers_detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ffe207-190b-4b17-bf6a-61cb095c65fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa1b24d-c03b-4d7e-b97e-2288c1f2d8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 848, 3)\n",
      "{'19': [133.0, 262.0], '17': [330.0, 254.0], '15': [508.0, 262.0], '13': [698.0, 265.0]}\n",
      "D400\n",
      "There is a depth camera with color sensor\n",
      "Depth Scale is:  0.0005000000237487257\n",
      "599.9999715015306\n",
      "00: Custom\n",
      "01: Default\n",
      "02: Hand\n",
      "03: High Accuracy\n",
      "04: High Density\n",
      "13yes\n",
      "0.27250000834465027\n",
      "Camera Points are: 0.12058735638856888 -0.006159485783427954 -0.27250000834465027\n",
      "[-361.3897763207874, -687.5800433915853, 121.91791923257078, 1.0]\n",
      "15yes\n",
      "0.0\n",
      "No depth info, Using an window\n",
      "0.22\n",
      "[503, 257]\n",
      "<class 'str'>\n",
      "[503, 257]\n",
      "<class 'list'>\n",
      "Camera Points are: 0.028018001466989517 -0.00383046455681324 -0.21700000762939453\n",
      "[-278.2800425300605, -688.7152984589893, 129.22246671908334, 1.0]\n",
      "17yes\n",
      "0.2005000114440918\n",
      "Camera Points are: -0.03298182040452957 -0.0008916961960494518 -0.2005000114440918\n",
      "[-229.12629432727954, -691.3408099178291, 134.32823921574382, 1.0]\n",
      "19yes\n",
      "0.1900000125169754\n",
      "Camera Points are: -0.09299582242965698 -0.0033538630232214928 -0.1900000125169754\n",
      "[-182.8471271698866, -690.2007953648035, 139.17942317992902, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import rtde_control\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "import time\n",
    "import points as p\n",
    "from statistics import mode\n",
    "import re\n",
    "\n",
    "import rtde_control\n",
    "import rtde_receive\n",
    "rtde_r = rtde_receive.RTDEReceiveInterface(\"169.254.37.182\")\n",
    "rtde_c = rtde_control.RTDEControlInterface(\"169.254.37.182\")\n",
    "# Parameters\n",
    "velocity = 0.5\n",
    "acceleration = 0.5\n",
    "dt = 1.0/500  # 2ms\n",
    "lookahead_time = 0.1\n",
    "gain = 300\n",
    "\n",
    "result_f={}\n",
    "depth_dict={}\n",
    "## dest_dict={}#########################################################################\n",
    "# rtde_c = rtde_control.RTDEControlInterface(\"169.254.37.182\")\n",
    "rtde_c.moveL([-0.30898, -0.64203, 0.19003, 0.032, -3.154, -0.017], 0.5, 0.3) #Capturing position\n",
    "time.sleep(1)\n",
    "num=p.point()\n",
    "print(num)\n",
    "\n",
    "def depth_filter(win_data):\n",
    "    x1,y1,x2,y2=win_data[0]-win_data[2]/2,win_data[1]-win_data[3]/2,win_data[0]+3*win_data[2]/2,win_data[1]+3*win_data[3]/2\n",
    "    for i in range(int(y1),int(y2)):\n",
    "        for j in range(int(x1),int(x2)):\n",
    "            d=aligned_depth_frame.get_distance(int(j),int(i))\n",
    "            if d!=0:\n",
    "                k=[j,i]\n",
    "                depth_dict[f'{k}']=round(d, 2)\n",
    "    depth_list=depth_dict.values()\n",
    "    filtered_depth=mode(depth_list)\n",
    "    print(filtered_depth)\n",
    "    corr_pix=list(depth_dict.keys())[list(depth_dict.values()).index(filtered_depth)] #get corresponding pixel of the distance value\n",
    "    print(corr_pix)\n",
    "    print(type(corr_pix))\n",
    "    #print(corr_pix) #A string here\n",
    "    corr_pix=re.split(', ',corr_pix)\n",
    "    pix_corr=[]\n",
    "    for num in corr_pix:\n",
    "        num=re.sub(r\"[\\([{})\\]]\", \"\", num)\n",
    "        num=int(num)\n",
    "        pix_corr.append(num)\n",
    "    \n",
    "    print(pix_corr)\n",
    "    print(type(pix_corr))\n",
    "    a,b=pix_corr[0],pix_corr[1]\n",
    "    depth=aligned_depth_frame.get_distance(int(a),int(b))\n",
    "    return depth\n",
    "def distance(x,y):\n",
    "    #cv2.circle(capture,(x,y),2,(128,0,128),-1)\n",
    "    #print((x,y))\n",
    "    d=depth_frame.get_distance(int(x),int(y))\n",
    "    print(d)\n",
    "    if (d==0.0) :\n",
    "        print('No depth info, Using an window')\n",
    "        depth=depth_filter([int(x),int(y),10,10])\n",
    "        x_w, y_w, z_w = convert_depth_to_phys_coord_using_realsense(int(x),int(y), depth, camera_info)\n",
    "        print('Camera Points are:',x_w, y_w, z_w)\n",
    "        p1=f'{x_w} {y_w} {z_w}'\n",
    "        p = [float(value) for value in p1.split(' ')]\n",
    "        p.append(1.0)\n",
    "        dst_p=np.matmul(k,p)\n",
    "        dst_p=dst_p.tolist()\n",
    "        print(dst_p)\n",
    "        rtde_c.moveL([dst_p[0]/1000.0, dst_p[1]/1000.0, dst_p[2]/1000.0, 0.032, -3.154, -0.017], 0.5, 0.3)\n",
    "        #time.sleep(5)\n",
    "        #dst_p=(dst_p[0])[:-1]\n",
    "        #print(dst_p)\n",
    "        del p1\n",
    "        del p\n",
    "    else:\n",
    "        x_w, y_w, z_w = convert_depth_to_phys_coord_using_realsense(int(x),int(y), d, camera_info)\n",
    "        print('Camera Points are:',x_w, y_w, z_w)\n",
    "        p1=f'{x_w} {y_w} {z_w}'\n",
    "        p = [float(value) for value in p1.split(' ')]\n",
    "        p.append(1.0)\n",
    "        dst_p=np.matmul(k,p)\n",
    "        dst_p=dst_p.tolist()\n",
    "        print(dst_p)\n",
    "        rtde_c.moveL([dst_p[0]/1000.0, dst_p[1]/1000.0, dst_p[2]/1000.0, 0.032, -3.154, -0.017], 0.5, 0.3)\n",
    "        #time.sleep(5)\n",
    "        #dst_p=(dst_p[0])[:-1]\n",
    "        #print(dst_p)\n",
    "        del p1\n",
    "        del p\n",
    "\n",
    "def convert_depth_to_phys_coord_using_realsense(x, y, depth, cameraInfo):\n",
    "    _intrinsics = rs.intrinsics()\n",
    "    _intrinsics.width = cameraInfo.width\n",
    "    _intrinsics.height = cameraInfo.height\n",
    "    _intrinsics.ppx = cameraInfo.ppx\n",
    "    _intrinsics.ppy = cameraInfo.ppy\n",
    "    _intrinsics.fx = cameraInfo.fx\n",
    "    _intrinsics.fy = cameraInfo.fy\n",
    "    # _intrinsics.model = cameraInfo.distortion_model\n",
    "    _intrinsics.model  = rs.distortion.none\n",
    "    _intrinsics.coeffs = [i for i in cameraInfo.coeffs]\n",
    "    result = rs.rs2_deproject_pixel_to_point(_intrinsics, [x, y], depth)\n",
    "    # result[0]: right, result[1]: down, result[2]: forward\n",
    "    return result[0], -result[1], -result[2]\n",
    "\"\"\"\n",
    "# Setup the pipeline\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)\n",
    "cfg.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)\n",
    "profile = pipe.start(cfg)\n",
    "\"\"\"\n",
    "\n",
    "k= [[-724.60538548,82.90733245,285.41238816,-195.72598377],[18.67714179,-740.17953151,41.7580128,-683.01233701],[-84.6609671,44.4134883,-11.45772205,129.27829634],[0,0,0,1]]\n",
    "\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = rs.pipeline()\n",
    "\n",
    "# Create a config and configure the pipeline to stream\n",
    "config = rs.config()\n",
    "pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "device = pipeline_profile.get_device()\n",
    "device_product_line = str(device.get_info(rs.camera_info.product_line))\n",
    "print(device_product_line)\n",
    "found_rgb = False\n",
    "for s in device.sensors:\n",
    "    if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "        found_rgb = True\n",
    "        print(\"There is a depth camera with color sensor\")\n",
    "        break\n",
    "if not found_rgb:\n",
    "    print(\"The demo requires Depth camera with Color sensor\")\n",
    "    exit(0)\n",
    "config.enable_stream(rs.stream.depth, 848,480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 848,480, rs.format.bgr8, 30)\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "\n",
    "# Setup the 'High Accuracy'-mode\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "print(\"Depth Scale is: \" , depth_scale)\n",
    "clipping_distance_in_meters = 0.3 #1 meter\n",
    "clipping_distance = clipping_distance_in_meters / depth_scale\n",
    "print(clipping_distance)\n",
    "preset_range = depth_sensor.get_option_range(rs.option.visual_preset)\n",
    "for i in range(int(preset_range.max)):\n",
    "    visulpreset = depth_sensor.get_option_value_description(rs.option.visual_preset,i)\n",
    "    print('%02d: %s'%(i,visulpreset))\n",
    "    if visulpreset == \"High Accuracy\":\n",
    "        depth_sensor.set_option(rs.option.visual_preset, i)\n",
    "# enable higher laser-power for better detection\n",
    "depth_sensor.set_option(rs.option.laser_power, 180)\n",
    "# lower the depth unit for better accuracy and shorter distance covered\n",
    "depth_sensor.set_option(rs.option.depth_units, 0.0005)\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "# Skip first frames for auto-exposure to adjust\n",
    "for x in range(5):\n",
    "    pipeline.wait_for_frames()\n",
    "t1=time.time()\n",
    "try:\n",
    "    while True:\n",
    "\n",
    "        # Stores next frameset\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "\n",
    "        if color_frame:\n",
    "            aligned_frames = align.process(frames)\n",
    "\n",
    "            # Get aligned frames\n",
    "            aligned_depth_frame = aligned_frames.get_depth_frame() # aligned_depth_frame is a 640x480 depth image\n",
    "            color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "            # Validate that both frames are valid\n",
    "            if not aligned_depth_frame or not color_frame:\n",
    "                continue\n",
    "\n",
    "            depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "            # Remove background - Set pixels further than clipping_distance to grey\n",
    "            black_color = 0\n",
    "            depth_image_3d = np.dstack((depth_image,depth_image,depth_image)) #depth image is 1 channel, color is 3 channels\n",
    "            bg_removed = np.where((depth_image_3d > clipping_distance) | (depth_image_3d <= 0), black_color, color_image)\n",
    "\n",
    "            # Render images:\n",
    "            #   depth align to color on left\n",
    "            #   depth on right\n",
    "            #depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "            #images = np.hstack((bg_removed, depth_colormap))\n",
    "            camera_info = aligned_depth_frame.profile.as_video_stream_profile().intrinsics\n",
    "            t2=time.time()\n",
    "            if (t2-t1)>3:\n",
    "                cv2.imwrite('captured.jpg',bg_removed)\n",
    "                # cv2.imshow('captured',bg_removed)\n",
    "                # cv2.waitKey(0)\n",
    "                # # cv2.destroyAllWindows()\n",
    "                break\n",
    "                \n",
    "finally:\n",
    "    numbers=list(num.keys())\n",
    "    z=13\n",
    "    rtde_c.moveL([-0.16780, -0.70145, 0.160, 0.036, -3.154, -0.017], 0.5, 0.3) #Capturing position\n",
    "    time.sleep(1)\n",
    "    \n",
    "\n",
    "    \n",
    "    for j in range(9):\n",
    "        if f'{z}' in numbers:\n",
    "            print(f'{z}yes')\n",
    "            val=num[f'{z}']\n",
    "            distance(val[0],val[1])\n",
    "            time.sleep(1)\n",
    "            #Rotate about Z\n",
    "            # Move to initial joint position with a regular moveJ\n",
    "            actual_q = rtde_r.getActualQ()\n",
    "            actual_q[5]-=1.57\n",
    "            rtde_c.moveJ(actual_q)\n",
    "            time.sleep(1)\n",
    "            ### Move downwards in Z axis\n",
    "            ### grip close to 80%\n",
    "            ### lifts the part in Z axis\n",
    "            ### Call the destination dictionary\n",
    "            ### grippen open \n",
    "            ### move in Z axis\n",
    "            z+=2\n",
    "            \n",
    "    \n",
    "    # Stop streaming\n",
    "    rtde_c.disconnect()\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbca8ce-5b48-44cb-907a-4c9b782f4c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
