{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aa1b24d-c03b-4d7e-b97e-2288c1f2d8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gripper...\n",
      "Connecting to gripper...\n",
      "Activating gripper...\n",
      "Gripper auto-calibrated to [3, 248]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 848, 3)\n",
      "{'19': [131.0, 263.0], '17': [329.0, 254.0], '20': [522.0, 258.0], '13': [698.0, 263.0]}\n",
      "D400\n",
      "There is a depth camera with color sensor\n",
      "Depth Scale is:  0.0005000000237487257\n",
      "599.9999715015306\n",
      "00: Custom\n",
      "01: Default\n",
      "02: Hand\n",
      "03: High Accuracy\n",
      "04: High Density\n",
      "13yes\n",
      "0.2710000276565552\n",
      "Camera Points are: 0.11992358416318893 -0.0052309720776975155 -0.2710000276565552\n",
      "[-360.40370972667654, -688.2170713864899, 121.99816700190686, 1.0]\n",
      "[7.456290273323475, 57.90370972667654, 118.80370972667652, 179.55370972667652, 240.55370972667654, 301.5537097266765, 359.3637097266765, 420.50370972667656, 485.40370972667654]\n",
      "1\n",
      "17yes\n",
      "0.19950000941753387\n",
      "Camera Points are: -0.03314640000462532 -0.0008872488397173584 -0.19950000941753387\n",
      "[-228.72125737769534, -691.3054175390571, 134.33091246119153, 1.0]\n",
      "[139.13874262230468, 73.77874262230466, 12.878742622304685, 47.871257377695315, 108.87125737769534, 169.87125737769534, 227.68125737769535, 288.82125737769536, 353.72125737769534]\n",
      "3\n",
      "19yes\n",
      "0.0\n",
      "No depth info, Using an window\n",
      "0.19\n",
      "[126, 258]\n",
      "<class 'str'>\n",
      "[126, 258]\n",
      "<class 'list'>\n",
      "Camera Points are: -0.09312988072633743 -0.0036481686402112246 -0.18900001049041748\n",
      "[-182.48897493320862, -689.9437020994895, 139.1662438006272, 1.0]\n",
      "[185.3710250667914, 120.01102506679138, 59.1110250667914, 1.6389749332086012, 62.63897493320863, 123.63897493320863, 181.44897493320863, 242.58897493320862, 307.4889749332086]\n",
      "4\n",
      "20yes\n",
      "0.0\n",
      "No depth info, Using an window\n",
      "0.19\n",
      "[126, 258]\n",
      "<class 'str'>\n",
      "[126, 258]\n",
      "<class 'list'>\n",
      "Camera Points are: 0.028767384588718414 -0.0020883814431726933 -0.18900001049041748\n",
      "[-270.6870720600864, -688.8215321481463, 128.91557902263546, 1.0]\n",
      "[97.17292793991362, 31.812927939913607, 29.08707206008637, 89.83707206008637, 150.8370720600864, 211.8370720600864, 269.6470720600864, 330.7870720600864, 395.6870720600864]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#Import\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import rtde_control\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "import time\n",
    "import points1 as p\n",
    "from statistics import mode\n",
    "import re\n",
    "\n",
    "import destination as pd\n",
    "dest=pd.dest_data()\n",
    "\n",
    "#Rtde Control\n",
    "import rtde_control\n",
    "import rtde_receive\n",
    "rtde_r = rtde_receive.RTDEReceiveInterface(\"169.254.37.182\")\n",
    "rtde_c = rtde_control.RTDEControlInterface(\"169.254.37.182\")\n",
    "\n",
    "#Gripper\n",
    "ip = \"169.254.37.182\"\n",
    "import robotiq_gripper\n",
    "def log_info(gripper):\n",
    "    print(f\"Pos: {str(gripper.get_current_position()): >3}  \"\n",
    "          f\"Open: {gripper.is_open(): <2}  \"\n",
    "          f\"Closed: {gripper.is_closed(): <2}  \")\n",
    "print(\"Creating gripper...\")\n",
    "gripper = robotiq_gripper.RobotiqGripper()\n",
    "print(\"Connecting to gripper...\")\n",
    "gripper.connect(ip, 63352)\n",
    "print(\"Activating gripper...\")\n",
    "gripper.activate()\n",
    "\n",
    "#Parameters\n",
    "velocity = 0.5\n",
    "acceleration = 0.5\n",
    "dt = 1.0/500  # 2ms\n",
    "lookahead_time = 0.1\n",
    "gain = 300\n",
    "\n",
    "#Jig Location Dictionary\n",
    "jig_coord={1:[-0.36786,-0.68974,0.1500,2.244,2.188,-0.005],2:[-0.3025, -0.690, 0.1498, 2.244, 2.188, -0.005],3:[-0.2416, -0.690, 0.150, 2.244, 2.188, -0.005],4:[-0.18085, -0.690, 0.1506, 2.244, 2.188, -0.005],5:[-0.11985, -0.690, 0.1500, 2.244, 2.188, -0.005],6:[-0.05885, -0.69, 0.1500, 2.244, 2.188, -0.005],7:[-0.00104, -0.690, 0.1500, 2.244, 2.188, -0.005],8:[0.0601, -0.6913, 0.1501, 2.244, 2.188, -0.005],9:[0.125,-0.6895,0.1502,2.244,2.188,-0.005]}\n",
    "\n",
    "## Pick and Place 11\n",
    "'''\n",
    "rtde_c.moveL([-0.53246, -0.58505, 0.114994, 2.223, 2.190, -0.018], 0.5, 0.3)\n",
    "rtde_c.moveL([-0.53250, -0.58502, -0.040002, 2.223, 2.190, -0.018], 0.5, 0.3)\n",
    "gripper.move_and_wait_for_pos(224, 255, 255)\n",
    "rtde_c.moveL([-0.53251, -0.585, 0.11496, 2.223, 2.19, -0.018], 0.5, 0.3)\n",
    "rtde_c.moveL([-0.27381, -0.45546, 0.04498, 2.232, 2.201, -0.005], 0.5, 0.3)\n",
    "rtde_c.moveL([-0.27383, -0.45555, 0.02471, 2.232, 2.201, -0.005], 0.5, 0.3)\n",
    "rtde_c.moveL([-0.30992, -0.45553, 0.02472, 2.232, 2.201, -0.005], 0.5, 0.3)\n",
    "gripper.move_and_wait_for_pos(0, 255, 255)\n",
    "rtde_c.moveL([-0.30992, -0.45553, 0.15, 2.232, 2.201, -0.005], 0.5, 0.3)\n",
    "'''\n",
    "result_f={}\n",
    "depth_dict={}\n",
    "\n",
    "## dest_dict={}#########################################################################\n",
    "# rtde_c = rtde_control.RTDEControlInterface(\"169.254.37.182\")\n",
    "\n",
    "#Capturing position\n",
    "rtde_c.moveL([-0.30898, -0.64203, 0.19003, 0.032, -3.154, -0.017], 0.5, 0.3) \n",
    "time.sleep(1)\n",
    "num=p.point()\n",
    "print(num)\n",
    "\n",
    "def depth_filter(win_data):\n",
    "    x1,y1,x2,y2=win_data[0]-win_data[2]/2,win_data[1]-win_data[3]/2,win_data[0]+3*win_data[2]/2,win_data[1]+3*win_data[3]/2\n",
    "    for i in range(int(y1),int(y2)):\n",
    "        for j in range(int(x1),int(x2)):\n",
    "            d=aligned_depth_frame.get_distance(int(j),int(i))\n",
    "            if d!=0:\n",
    "                k=[j,i]\n",
    "                depth_dict[f'{k}']=round(d, 2)\n",
    "    depth_list=depth_dict.values()\n",
    "    filtered_depth=mode(depth_list)\n",
    "    print(filtered_depth)\n",
    "    corr_pix=list(depth_dict.keys())[list(depth_dict.values()).index(filtered_depth)] #get corresponding pixel of the distance value\n",
    "    print(corr_pix)\n",
    "    print(type(corr_pix))\n",
    "    #print(corr_pix) #A string here\n",
    "    corr_pix=re.split(', ',corr_pix)\n",
    "    pix_corr=[]\n",
    "    for num in corr_pix:\n",
    "        num=re.sub(r\"[\\([{})\\]]\", \"\", num)\n",
    "        num=int(num)\n",
    "        pix_corr.append(num)\n",
    "    \n",
    "    print(pix_corr)\n",
    "    print(type(pix_corr))\n",
    "    a,b=pix_corr[0],pix_corr[1]\n",
    "    depth=aligned_depth_frame.get_distance(int(a),int(b))\n",
    "    return depth\n",
    "def distance(x,y,kt):\n",
    "    #cv2.circle(capture,(x,y),2,(128,0,128),-1)\n",
    "    #print((x,y))\n",
    "    d=depth_frame.get_distance(int(x),int(y))\n",
    "    print(d)\n",
    "    if (d==0.0) :\n",
    "        print('No depth info, Using an window')\n",
    "        depth=depth_filter([int(x),int(y),10,10])\n",
    "        x_w, y_w, z_w = convert_depth_to_phys_coord_using_realsense(int(x),int(y), depth, camera_info)\n",
    "        print('Camera Points are:',x_w, y_w, z_w)\n",
    "        p1=f'{x_w} {y_w} {z_w}'\n",
    "        p = [float(value) for value in p1.split(' ')]\n",
    "        p.append(1.0)\n",
    "        dst_p=np.matmul(kt,p)\n",
    "        dst_p=dst_p.tolist()\n",
    "        print(dst_p)\n",
    "        #rtde_c.moveL([dst_p[0]/1000.0, dst_p[1]/1000.0, dst_p[2]/1000.0, 0.032, -3.154, -0.017], 0.5, 0.3)\n",
    "        #time.sleep(5)\n",
    "        #dst_p=(dst_p[0])[:-1]\n",
    "        #print(dst_p)\n",
    "        obj1=dst_p[0]\n",
    "        list=[]\n",
    "        for i in range(1,10):\n",
    "            list.append(abs(obj1-(jig_coord[i][0]*1000)))\n",
    "        obj1abs=list.index(min(list))+1\n",
    "        print(list)\n",
    "        print(obj1abs)\n",
    "        rtde_c.moveL(jig_coord[obj1abs], 0.5, 0.3)\n",
    "        del list\n",
    "        del p1\n",
    "        del p\n",
    "    else:\n",
    "        x_w, y_w, z_w = convert_depth_to_phys_coord_using_realsense(int(x),int(y), d, camera_info)\n",
    "        print('Camera Points are:',x_w, y_w, z_w)\n",
    "        p1=f'{x_w} {y_w} {z_w}'\n",
    "        p = [float(value) for value in p1.split(' ')]\n",
    "        p.append(1.0)\n",
    "        dst_p=np.matmul(kt,p)\n",
    "        dst_p=dst_p.tolist()\n",
    "        print(dst_p)\n",
    "        #rtde_c.moveL([dst_p[0]/1000.0, dst_p[1]/1000.0, dst_p[2]/1000.0, 0.032, -3.154, -0.017], 0.5, 0.3)\n",
    "        #time.sleep(5)\n",
    "        #dst_p=(dst_p[0])[:-1]\n",
    "        #print(dst_p)\n",
    "        obj1=dst_p[0]\n",
    "        list=[]\n",
    "        for i in range(1,10):\n",
    "            list.append(abs(obj1-(jig_coord[i][0]*1000)))\n",
    "        print(list)\n",
    "        obj1abs=list.index(min(list))+1\n",
    "        print(obj1abs)\n",
    "        rtde_c.moveL(jig_coord[obj1abs], 0.5, 0.3)\n",
    "        del list\n",
    "        del p1\n",
    "        del p\n",
    "def convert_depth_to_phys_coord_using_realsense(x, y, depth, cameraInfo):\n",
    "    _intrinsics = rs.intrinsics()\n",
    "    _intrinsics.width = cameraInfo.width\n",
    "    _intrinsics.height = cameraInfo.height\n",
    "    _intrinsics.ppx = cameraInfo.ppx\n",
    "    _intrinsics.ppy = cameraInfo.ppy\n",
    "    _intrinsics.fx = cameraInfo.fx\n",
    "    _intrinsics.fy = cameraInfo.fy\n",
    "    # _intrinsics.model = cameraInfo.distortion_model\n",
    "    _intrinsics.model  = rs.distortion.none\n",
    "    _intrinsics.coeffs = [i for i in cameraInfo.coeffs]\n",
    "    result = rs.rs2_deproject_pixel_to_point(_intrinsics, [x, y], depth)\n",
    "    # result[0]: right, result[1]: down, result[2]: forward\n",
    "    return result[0], -result[1], -result[2]\n",
    "\"\"\"\n",
    "# Setup the pipeline\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)\n",
    "cfg.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)\n",
    "profile = pipe.start(cfg)\n",
    "\"\"\"\n",
    "\n",
    "kl= [[-724.60538548,82.90733245,285.41238816,-195.72598377],[18.67714179,-740.17953151,41.7580128,-683.01233701],[-84.6609671,44.4134883,-11.45772205,129.27829634],[0.0,0.0,0.0,1.0]]\n",
    "\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = rs.pipeline()\n",
    "\n",
    "# Create a config and configure the pipeline to stream\n",
    "config = rs.config()\n",
    "pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "device = pipeline_profile.get_device()\n",
    "device_product_line = str(device.get_info(rs.camera_info.product_line))\n",
    "print(device_product_line)\n",
    "found_rgb = False\n",
    "for s in device.sensors:\n",
    "    if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "        found_rgb = True\n",
    "        print(\"There is a depth camera with color sensor\")\n",
    "        break\n",
    "if not found_rgb:\n",
    "    print(\"The demo requires Depth camera with Color sensor\")\n",
    "    exit(0)\n",
    "config.enable_stream(rs.stream.depth, 848,480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 848,480, rs.format.bgr8, 30)\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "\n",
    "# Setup the 'High Accuracy'-mode\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "print(\"Depth Scale is: \" , depth_scale)\n",
    "clipping_distance_in_meters = 0.3 #1 meter\n",
    "clipping_distance = clipping_distance_in_meters / depth_scale\n",
    "print(clipping_distance)\n",
    "preset_range = depth_sensor.get_option_range(rs.option.visual_preset)\n",
    "for i in range(int(preset_range.max)):\n",
    "    visulpreset = depth_sensor.get_option_value_description(rs.option.visual_preset,i)\n",
    "    print('%02d: %s'%(i,visulpreset))\n",
    "    if visulpreset == \"High Accuracy\":\n",
    "        depth_sensor.set_option(rs.option.visual_preset, i)\n",
    "# enable higher laser-power for better detection\n",
    "depth_sensor.set_option(rs.option.laser_power, 180)\n",
    "# lower the depth unit for better accuracy and shorter distance covered\n",
    "depth_sensor.set_option(rs.option.depth_units, 0.0005)\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "# Skip first frames for auto-exposure to adjust\n",
    "for x in range(5):\n",
    "    pipeline.wait_for_frames()\n",
    "t1=time.time()\n",
    "try:\n",
    "    while True:\n",
    "\n",
    "        # Stores next frameset\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "\n",
    "        if color_frame:\n",
    "            aligned_frames = align.process(frames)\n",
    "            # Get aligned frames\n",
    "            aligned_depth_frame = aligned_frames.get_depth_frame() # aligned_depth_frame is a 640x480 depth image\n",
    "            color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "            # Validate that both frames are valid\n",
    "            if not aligned_depth_frame or not color_frame:\n",
    "                continue\n",
    "\n",
    "            depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "            # Remove background - Set pixels further than clipping_distance to grey\n",
    "            black_color = 0\n",
    "            depth_image_3d = np.dstack((depth_image,depth_image,depth_image)) #depth image is 1 channel, color is 3 channels\n",
    "            bg_removed = np.where((depth_image_3d > clipping_distance) | (depth_image_3d <= 0), black_color, color_image)\n",
    "\n",
    "            # Render images:\n",
    "            #   depth align to color on left\n",
    "            #   depth on right\n",
    "            #depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "            #images = np.hstack((bg_removed, depth_colormap))\n",
    "            camera_info = aligned_depth_frame.profile.as_video_stream_profile().intrinsics\n",
    "            t2=time.time()\n",
    "            if (t2-t1)>3:\n",
    "                cv2.imwrite('captured1.jpg',bg_removed)\n",
    "                # cv2.imshow('captured',bg_removed)\n",
    "                # cv2.waitKey(0)\n",
    "                # # cv2.destroyAllWindows()\n",
    "                break\n",
    "                \n",
    "finally:\n",
    "    numbers=list(num.keys())\n",
    "    z=13\n",
    "    #rtde_c.moveL([-0.16780, -0.70145, 0.160, 0.036, -3.154, -0.017], 0.5, 0.3) #Capturing position\n",
    "    time.sleep(1)\n",
    "\n",
    "    for j in range(9):\n",
    "        if f'{z}' in numbers:\n",
    "            print(f'{z}yes')\n",
    "            val=num[f'{z}']\n",
    "            distance(val[0],val[1],kl)\n",
    "            time.sleep(1)\n",
    "            \n",
    "            ### Move downwards in Z axis\n",
    "            actual_p=rtde_r.getActualTCPPose()\n",
    "            z_pos=actual_p[2]\n",
    "            actual_p[2]=0.015\n",
    "            rtde_c.moveL(actual_p)\n",
    "            ### grip close to 80%\n",
    "            gripper.move_and_wait_for_pos(224, 255, 255)\n",
    "            ### lifts the part in Z axis\n",
    "            actual_p2=rtde_r.getActualTCPPose()\n",
    "            actual_p2[2]=z_pos\n",
    "            rtde_c.moveL(actual_p2)\n",
    "            ### Call the destination dictionary\n",
    "            for k in range(3):\n",
    "                rtde_c.moveL(dest[z][k], 0.5, 0.3)\n",
    "            ### grippen open \n",
    "            gripper.move_and_wait_for_pos(0, 255, 255)\n",
    "            ### move in Z axis\n",
    "            actual_c=rtde_r.getActualTCPPose()\n",
    "            actual_c[2]+=0.115\n",
    "            rtde_c.moveL(actual_c)\n",
    "            \n",
    "        z+=1\n",
    "    \n",
    "    # Stop streaming\n",
    "    rtde_c.disconnect()\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d037a728-3bec-41de-b0da-1ac61744d3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
