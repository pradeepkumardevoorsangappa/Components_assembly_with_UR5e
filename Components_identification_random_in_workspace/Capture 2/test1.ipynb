{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55d43c95-d2a2-4349-912d-83878b995ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D400\n",
      "There is a depth camera with color sensor\n",
      "Depth Scale is:  0.0005000000237487257\n",
      "599.9999715015306\n",
      "00: Custom\n",
      "01: Default\n",
      "02: Hand\n",
      "03: High Accuracy\n",
      "04: High Density\n",
      "1\n",
      "(336, 199)\n",
      "0.2175000160932541\n",
      "Camera Points are: -0.03362567350268364 0.018777625635266304 -0.2175000160932541\n",
      "[61.366259778862165, -706.5476424753098, 134.88266467223033, 1.0]\n",
      "1\n",
      "(511, 189)\n",
      "0.0\n",
      "No depth info, You must use an window\n",
      "1\n",
      "(507, 183)\n",
      "0.0\n",
      "No depth info, You must use an window\n",
      "1\n",
      "(504, 194)\n",
      "0.0\n",
      "No depth info, You must use an window\n",
      "1\n",
      "(529, 189)\n",
      "0.0\n",
      "No depth info, You must use an window\n",
      "1\n",
      "(527, 172)\n",
      "0.0\n",
      "No depth info, You must use an window\n",
      "1\n",
      "(561, 265)\n",
      "0.18900001049041748\n",
      "Camera Points are: 0.04092593491077423 -0.004272083751857281 -0.18900001049041748\n",
      "[-16.825685725454818, -684.2645804461487, 132.20062908469077, 1.0]\n",
      "1\n",
      "(683, 213)\n",
      "0.0\n",
      "No depth info, You must use an window\n",
      "1\n",
      "(747, 244)\n",
      "0.0\n",
      "No depth info, You must use an window\n",
      "1\n",
      "(694, 270)\n",
      "0.0\n",
      "No depth info, You must use an window\n",
      "1\n",
      "(713, 124)\n",
      "0.2915000021457672\n",
      "Camera Points are: 0.13620777428150177 0.06125188618898392 -0.2915000021457672\n",
      "[-91.52703435221937, -746.2831474245216, 195.8511764210915, 1.0]\n",
      "1\n",
      "(691, 186)\n",
      "0.0\n",
      "No depth info, You must use an window\n",
      "1\n",
      "(717, 237)\n",
      "0.0\n",
      "No depth info, You must use an window\n",
      "1\n",
      "(694, 339)\n",
      "0.0\n",
      "No depth info, You must use an window\n",
      "1\n",
      "(672, 260)\n",
      "0.0\n",
      "No depth info, You must use an window\n",
      "1\n",
      "(513, 301)\n",
      "0.0\n",
      "No depth info, You must use an window\n",
      "1\n",
      "(514, 267)\n",
      "0.0\n",
      "No depth info, You must use an window\n",
      "1\n",
      "(460, 252)\n",
      "0.19600000977516174\n",
      "Camera Points are: 0.009787976741790771 -0.00022466016525868326 -0.19600000977516174\n",
      "[14.94070056475265, -688.1767248689869, 130.78345586025796, 1.0]\n",
      "1\n",
      "(377, 287)\n",
      "0.0\n",
      "No depth info, You must use an window\n",
      "1\n",
      "(293, 233)\n",
      "0.22800001502037048\n",
      "Camera Points are: -0.051420796662569046 0.006888923700898886 -0.22800001502037048\n",
      "[80.68944479100213, -694.5945861745894, 135.7900199826097, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import rtde_control\n",
    "import time\n",
    "\n",
    "rtde_c = rtde_control.RTDEControlInterface(\"169.254.37.182\")\n",
    "rtde_c.moveL([-0.00772, -0.64201, 0.19098, 0.032, -3.154, -0.017], 0.5, 0.3)\n",
    "def distance(event,x,y,flags,param):\n",
    "    if event==cv2.EVENT_LBUTTONDOWN:\n",
    "        print(event)\n",
    "        cv2.circle(capture,(x,y),2,(128,0,128),-1)\n",
    "        print((x,y))\n",
    "        d=depth_frame.get_distance(int(x),int(y))\n",
    "        print(d)\n",
    "        if (d==0.0) :\n",
    "            print('No depth info, You must use an window')\n",
    "        else:\n",
    "            x_w, y_w, z_w = convert_depth_to_phys_coord_using_realsense(int(x),int(y), d, camera_info)\n",
    "            print('Camera Points are:',x_w, y_w, z_w)\n",
    "            p1=f'{x_w} {y_w} {z_w}'\n",
    "            p = [float(value) for value in p1.split(' ')]\n",
    "            p.append(1.0)\n",
    "            dst_p=np.matmul(k,p)\n",
    "            dst_p=dst_p.tolist()\n",
    "            print(dst_p)\n",
    "            rtde_c.moveL([dst_p[0]/1000.0, dst_p[1]/1000.0, dst_p[2]/1000.0, 0.032, -3.154, -0.017], 0.5, 0.3)\n",
    "            #time.sleep(5)\n",
    "            #dst_p=(dst_p[0])[:-1]\n",
    "            #print(dst_p)\n",
    "            del p1\n",
    "            del p\n",
    "\n",
    "def convert_depth_to_phys_coord_using_realsense(x, y, depth, cameraInfo):\n",
    "    _intrinsics = rs.intrinsics()\n",
    "    _intrinsics.width = cameraInfo.width\n",
    "    _intrinsics.height = cameraInfo.height\n",
    "    _intrinsics.ppx = cameraInfo.ppx\n",
    "    _intrinsics.ppy = cameraInfo.ppy\n",
    "    _intrinsics.fx = cameraInfo.fx\n",
    "    _intrinsics.fy = cameraInfo.fy\n",
    "    # _intrinsics.model = cameraInfo.distortion_model\n",
    "    _intrinsics.model  = rs.distortion.none\n",
    "    _intrinsics.coeffs = [i for i in cameraInfo.coeffs]\n",
    "    result = rs.rs2_deproject_pixel_to_point(_intrinsics, [x, y], depth)\n",
    "    # result[0]: right, result[1]: down, result[2]: forward\n",
    "    return result[0], -result[1], -result[2]\n",
    "\"\"\"\n",
    "# Setup the pipeline\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)\n",
    "cfg.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)\n",
    "profile = pipe.start(cfg)\n",
    "\"\"\"\n",
    "k= [[-9.79365051e+02,6.22173726e-01,-1.81205747e+02,-1.09894855e+01],[2.63002626e+00,-9.88050938e+02,-2.41157019e+01,-6.93151121e+02],[1.52250424e+02,7.62100894e+01,-4.30734272e+02,4.48864321e+01],[0.00000000e+00,0.00000000e+00,0.00000000e+00,1.00000000e+00]]\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = rs.pipeline()\n",
    "\n",
    "# Create a config and configure the pipeline to stream\n",
    "config = rs.config()\n",
    "pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "device = pipeline_profile.get_device()\n",
    "device_product_line = str(device.get_info(rs.camera_info.product_line))\n",
    "print(device_product_line)\n",
    "found_rgb = False\n",
    "for s in device.sensors:\n",
    "    if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "        found_rgb = True\n",
    "        print(\"There is a depth camera with color sensor\")\n",
    "        break\n",
    "if not found_rgb:\n",
    "    print(\"The demo requires Depth camera with Color sensor\")\n",
    "    exit(0)\n",
    "config.enable_stream(rs.stream.depth, 848, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 848, 480, rs.format.bgr8, 30)\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "\n",
    "# Setup the 'High Accuracy'-mode\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "print(\"Depth Scale is: \" , depth_scale)\n",
    "clipping_distance_in_meters = 0.3 #1 meter\n",
    "clipping_distance = clipping_distance_in_meters / depth_scale\n",
    "print(clipping_distance)\n",
    "preset_range = depth_sensor.get_option_range(rs.option.visual_preset)\n",
    "for i in range(int(preset_range.max)):\n",
    "    visulpreset = depth_sensor.get_option_value_description(rs.option.visual_preset,i)\n",
    "    print('%02d: %s'%(i,visulpreset))\n",
    "    if visulpreset == \"High Accuracy\":\n",
    "        depth_sensor.set_option(rs.option.visual_preset, i)\n",
    "# enable higher laser-power for better detection\n",
    "depth_sensor.set_option(rs.option.laser_power, 180)\n",
    "# lower the depth unit for better accuracy and shorter distance covered\n",
    "depth_sensor.set_option(rs.option.depth_units, 0.0005)\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "# Skip first frames for auto-exposure to adjust\n",
    "for x in range(5):\n",
    "    pipeline.wait_for_frames()\n",
    "try:\n",
    "    while True:\n",
    "\n",
    "        # Stores next frameset\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "\n",
    "        if color_frame:\n",
    "            aligned_frames = align.process(frames)\n",
    "\n",
    "            # Get aligned frames\n",
    "            aligned_depth_frame = aligned_frames.get_depth_frame() # aligned_depth_frame is a 640x480 depth image\n",
    "            color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "            # Validate that both frames are valid\n",
    "            if not aligned_depth_frame or not color_frame:\n",
    "                continue\n",
    "\n",
    "            depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "            # Remove background - Set pixels further than clipping_distance to grey\n",
    "            black_color = 0\n",
    "            depth_image_3d = np.dstack((depth_image,depth_image,depth_image)) #depth image is 1 channel, color is 3 channels\n",
    "            bg_removed = np.where((depth_image_3d > clipping_distance) | (depth_image_3d <= 0), black_color, color_image)\n",
    "\n",
    "            # Render images:\n",
    "            #   depth align to color on left\n",
    "            #   depth on right\n",
    "            #depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "            #images = np.hstack((bg_removed, depth_colormap))\n",
    "            cv2.namedWindow('depth_cut', cv2.WINDOW_NORMAL)\n",
    "            cv2.imshow('depth_cut', bg_removed)\n",
    "            camera_info = aligned_depth_frame.profile.as_video_stream_profile().intrinsics\n",
    "            if cv2.waitKey(1) & 0xFF==27:\n",
    "                capture=bg_removed\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "\n",
    "finally:\n",
    "    while True:\n",
    "        cv2.imshow('object',capture)\n",
    "        cv2.setMouseCallback('object',distance)\n",
    "        if cv2.waitKey(10) & 0xFF==27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    # Stop streaming\n",
    "    rtde_c.disconnect()\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4443f-9c42-408a-b49d-3895375733f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1.55, 5.66, 5.22, 1.0]\n",
    "b=[1.2,5,2]\n",
    "k=[a[0]/10.0,a[1]/10.0,b[0],b[1]]\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8a730d-b855-4014-be54-da68e10f7bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
